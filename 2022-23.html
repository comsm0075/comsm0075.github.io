

<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<font face="verdana, Sans-serif">
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="GENERATOR" content="Mozilla/4.51 [en] (X11; I; OSF1 V4.0 alpha) [Netscape]">
   <title>COMSM0075
</title>
</head>

<body  bgcolor=white link="slategrey" vlink="darkslategrey" alink="darkslategrey">

  <table>
    <tbody>
      <tr>
	<td bgcolor="slategrey" width="30">&nbsp;</td>
	
	<td bgcolor="darkslategrey" width="1">&nbsp;</td>
	<td bgcolor=white width="10">&nbsp;</td>
	
	<td width="15"> 
	<td>
	  
	  <h1 style="color: darkslategrey">COMSM0075</h1><p>
	    
	    <h2 style="color: darkslategrey">Week 1 - CH - information theory</h2>
	    <ul>
	      <li><b>lecture 1</b>: introduction to the unit, motivation, definition of entropy and some of its properties. This corresponds to, roughly, the first four pages of "notes1".</li>
	      <li><b>notes1</b> lecture notes for information theory <a href="https://github.com/comsm0075/2022_23/raw/master/1_information_theory/notes1_information.pdf">pdf</a></li>
	      <li>old online lecture motivating Shannon's entropy <a href="https://www.youtube.com/watch?v=aD7PCVgdPzU">youtube</a> / <a href="https://github.com/comsm0075/2022_23/raw/master/1_information_theory/slides1.pdf">slides (pdf)</a></li>
	      <li><b>lecture 2</b>: more on information theory, the source coding theorem, joint and conditional entropy, mutual information and the information processing inequality. This completes the material in "notes1"; the slides linked below are worth looking at I believe.</li>
	      <li>old online lecture: Shannon's entropy <a href="https://www.youtube.com/watch?v=aeP3JsceyxY">youtube</a> / <a href="https://github.com/comsm0075/2021_22/raw/master/1_information_theory/slides2.pdf">slides (pdf)</a></li>
<li>old online lecture: joint and conditional entropy <a href="https://youtu.be/4N4nKGWun40">youtube</a> / <a href="https://github.com/comsm0075/2021_22/raw/master/1_information_theory/slides3.pdf">slides (pdf)</a></li>
<li>old online lecture: mutual information <a href="https://youtu.be/vYPR5_docCE">youtube</a> / <a href="https://github.com/comsm0075/2021_22/raw/master/1_information_theory/slides4.pdf">slides (pdf)</a></li>
	      <li>old online lecture: the data processing inequality <a href="https://youtu.be/6s1JpK0PbnA">youtube</a> / <a href="https://github.com/comsm0075/2021_22/raw/master/1_information_theory/slides5.pdf">slides (pdf)</a></li>
	      
</ul>
	    <h2 style="color: darkslategrey">Week 2 - CH - information theory in the brain</h2>

	    <h2 style="color: darkslategrey">Week 3 - CH - the Bayesian Brain / Kalman filters</h2>

	    <h2 style="color: darkslategrey">Week 4 - RPC - Neural circuits and learning</h2>

	    <h2 style="color: darkslategrey">Week 5 - RPC - Neural circuits and learning</h2>

	    <h2 style="color: darkslategrey">Week 6 - Reading week</h2>

	    <h2 style="color: darkslategrey">Week 7 - RPC - Neural circuits and learning</h2>

	    <h2 style="color: black">Week 8 - RPC - Neural circuits and learning</h2>

	    <h2 style="color: darkslategrey">Week 9 - 11 Coursework weeks</h2>    
	    
</body>
</html>
